{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "gather": {
          "logged": 1746365640933
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hello azue ML\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "print(\"Hello azue ML\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "To create a simple neural network in PyTorch for sentence classification (valid grammar or not), we'll need to follow a few key steps:\n",
        "\n",
        "1. Prepare the data: Create a dataset with sentences labeled as \"valid\" or \"invalid.\"\n",
        "2. Tokenize the sentences: Convert sentences into numerical representations (e.g., using tokenization and embedding).\n",
        "3. Create the model: Define a simple neural network architecture.\n",
        "4. Train the model: Use the training data to optimize the model.\n",
        "5. Evaluate the model: Test the model's performance on a test set.\n",
        "\n",
        "# 1. Prepare dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "gather": {
          "logged": 1746365158219
        }
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "from collections import Counter\n",
        "import string\n",
        "\n",
        "# Toy dataset with sentences and labels (1 for valid, 0 for invalid)\n",
        "data = [\n",
        "    (\"The cat sat on the mat\", 1),\n",
        "    (\"This is a valid sentence\", 1),\n",
        "    (\"Sentence incorrect word\", 0),\n",
        "    (\"Invalid sentence test word\", 0),\n",
        "    (\"The quick brown fox jumps over\", 0),\n",
        "    (\"A valid grammatical sentence\", 1),\n",
        "    (\"Me very good at this\", 0)\n",
        "]\n",
        "\n",
        "# Preprocessing the sentences by tokenizing and converting to lowercase\n",
        "def preprocess(sentence):\n",
        "    return sentence.translate(str.maketrans('', '', string.punctuation)).lower().split()\n",
        "\n",
        "# Create a vocabulary\n",
        "all_words = [word for sentence, _ in data for word in preprocess(sentence)]\n",
        "vocab = {word: idx + 1 for idx, (word, _) in enumerate(Counter(all_words).items())}\n",
        "vocab['<PAD>'] = 0  # Padding token\n",
        "\n",
        "# Define a custom dataset for loading\n",
        "class SentenceDataset(Dataset):\n",
        "    def __init__(self, data, vocab):\n",
        "        self.data = data\n",
        "        self.vocab = vocab\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        sentence, label = self.data[idx]\n",
        "        tokenized_sentence = preprocess(sentence)\n",
        "        # Convert tokens to indices\n",
        "        sentence_indices = [self.vocab.get(word, 0) for word in tokenized_sentence]\n",
        "        return torch.tensor(sentence_indices), torch.tensor(label)\n",
        "\n",
        "# Custom collate function for padding\n",
        "def collate_fn(batch):\n",
        "    sentences, labels = zip(*batch)\n",
        "    # Pad sentences to the maximum length in the batch\n",
        "    sentences_padded = pad_sequence(sentences, batch_first=True, padding_value=0)\n",
        "    labels = torch.tensor(labels)\n",
        "    return sentences_padded, labels\n",
        "\n",
        "dataset = SentenceDataset(data, vocab)\n",
        "dataloader = DataLoader(dataset, batch_size=2, shuffle=True, collate_fn=collate_fn)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "# 2. Create the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "gather": {
          "logged": 1746365207207
        }
      },
      "outputs": [],
      "source": [
        "class SentenceClassifier(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim):\n",
        "        super(SentenceClassifier, self).__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=0)\n",
        "        self.rnn = nn.LSTM(embedding_dim, hidden_dim, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.embedding(x)\n",
        "        _, (hn, _) = self.rnn(x)\n",
        "        out = self.fc(hn[-1])\n",
        "        return torch.sigmoid(out)\n",
        "\n",
        "# Define model parameters\n",
        "vocab_size = len(vocab)\n",
        "embedding_dim = 8\n",
        "hidden_dim = 16\n",
        "output_dim = 1\n",
        "\n",
        "model = SentenceClassifier(vocab_size, embedding_dim, hidden_dim, output_dim)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "# 3. Train the model\n",
        "\n",
        "Now let's define the training loop to optimize the model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "gather": {
          "logged": 1746365225860
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/10], Loss: 0.6927, Accuracy: 0.7143\n",
            "Epoch [2/10], Loss: 0.6930, Accuracy: 0.5714\n",
            "Epoch [3/10], Loss: 0.6898, Accuracy: 0.5714\n",
            "Epoch [4/10], Loss: 0.6898, Accuracy: 0.5714\n",
            "Epoch [5/10], Loss: 0.6892, Accuracy: 0.5714\n",
            "Epoch [6/10], Loss: 0.6924, Accuracy: 0.5714\n",
            "Epoch [7/10], Loss: 0.6916, Accuracy: 0.5714\n",
            "Epoch [8/10], Loss: 0.6850, Accuracy: 0.5714\n",
            "Epoch [9/10], Loss: 0.6910, Accuracy: 0.5714\n",
            "Epoch [10/10], Loss: 0.6910, Accuracy: 0.5714\n"
          ]
        }
      ],
      "source": [
        "# Loss function and optimizer\n",
        "criterion = nn.BCELoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Training loop\n",
        "num_epochs = 10\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for sentences, labels in dataloader:\n",
        "        # Pad sentences to have the same length\n",
        "        sentences = torch.nn.functional.pad(sentences, (0, 10 - sentences.size(1)), value=0)  # Padding length 10\n",
        "        labels = labels.float().view(-1, 1)\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        # Forward pass\n",
        "        outputs = model(sentences)\n",
        "        loss = criterion(outputs, labels)\n",
        "        \n",
        "        # Backward pass\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        total_loss += loss.item()\n",
        "        \n",
        "        # Calculate accuracy\n",
        "        predicted = (outputs > 0.5).float()\n",
        "        correct += (predicted == labels).sum().item()\n",
        "        total += labels.size(0)\n",
        "\n",
        "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {total_loss/len(dataloader):.4f}, Accuracy: {correct/total:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "# 4. Evaluate the Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "gather": {
          "logged": 1746365273765
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sentence: 'Me very good at this' - Invalid Grammar\n"
          ]
        }
      ],
      "source": [
        "def evaluate(model, sentence, vocab):\n",
        "    model.eval()\n",
        "    sentence_indices = [vocab.get(word, 0) for word in preprocess(sentence)]\n",
        "    sentence_tensor = torch.tensor(sentence_indices).unsqueeze(0)\n",
        "    sentence_tensor = torch.nn.functional.pad(sentence_tensor, (0, 10 - sentence_tensor.size(1)), value=0)\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        output = model(sentence_tensor)\n",
        "        prediction = (output > 0.5).item()\n",
        "        return \"Valid Grammar\" if prediction == 1 else \"Invalid Grammar\"\n",
        "\n",
        "# Test the model\n",
        "test_sentence = \"Me very good at this\"\n",
        "result = evaluate(model, test_sentence, vocab)\n",
        "print(f\"Sentence: '{test_sentence}' - {result}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "python38-azureml-pt-tf"
    },
    "kernelspec": {
      "display_name": "Python 3.10 - Pytorch and Tensorflow",
      "language": "python",
      "name": "python38-azureml-pt-tf"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.16"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      },
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
